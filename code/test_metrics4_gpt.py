import json
import pandas as pd
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import openai
import re
import csv


openai.api_key = ""



def extract_score(text):
    match = re.search('Score:\s*(\d+(?:\.\d+)?)', text)
    if match:
        return float(match.group(1))
    else:
        return None
def generate_response0(prompt,model):
    #intruduction of the task
    # messeage_head = "Task: Generate a high-quality student question that corresponds to the teacher response. I will provide you with a sentence as the teacher's response, which is the answer to the student's question.\n\nInstructions:\n\n1 Your generated student question should be related to the content of the sentence and demonstrate an understanding of the concept or topic discussed in the sentence.\n2 The teacher's response should be unchanged, just put it into json\n3 Use the following JSON format for the dialogue:\n{\"dialogues\": [{\"speaker\": \"student\",\"text\": \"\"},{ \"speaker\": \"teacher\",\"text\": \"\"}]}\n4 When generating a student question, try to put yourself in the shoes of someone who is genuinely curious and wants to learn more about the topic.\n5 Be creative and try to generate a question that a curious student might ask in a real classroom setting.\n6 Only output one JSON variable, do not output anything else!\n7 the teacher's response is: "
    #define the format of the output
    # messeage_end = '\n\nYou should generate one question for one sentence, and the sentence should be the answer for your question. Your question should be high quality and like human. Generate question in the following JSON format, the sentence should be in teacher place, while your question should be in student place:{  "dialogues": [  {  "speaker": "student",  "text": ""  },  {  "speaker": "teacher",  "text": ""  },...  ]}'
    #combine the introduction and the prompt into the input
    messeage_content = prompt

    # print(messeage_content)
    completion = openai.ChatCompletion.create(
        # model="gpt-3.5-turbo", 
        model=model,
        messages=[{"role": "user", "content": messeage_content}]
    )

    return completion
def calculate_coherence_score(dialog):
    
    dialog_str = "\n".join([f"Teacher asks: {dialog[i]}\nStudent answers: {dialog[i+1]}" for i in range(0, len(dialog), 2)])
    
    prompt = f"Assuming you are a linguistic expert, your task is to assess the coherence of the following dialogue generated by an AI system. This dialogue is structured as a teacher-student interaction centered around teaching a passage from a textbook, only the teacher part is generated by AI. When we say 'coherence', we're asking: Does the dialogue logically flow and stay consistent with the conversation's context? Does the AI-generated dialogue maintain the thematic context from beginning to end? Please provide a coherence score from 0 to 10, where 0 signifies no coherence and 10 denotes excellent coherence. The dialog is: \n\n{dialog_str}\n\n Please provide me with the score only in your response in this format: Score:<number>"
    print('prompt:',prompt)
    print('__________________________generated______________________________________________')
    # inputs = tokenizer.encode(prompt, return_tensors='pt', truncation=True, max_length=512)
    # outputs = model.generate(inputs, max_length=512, do_sample=True)
    result = generate_response0(prompt,'gpt-4-0314')
    input_string = result['choices'][0]['message']['content']
    
    return extract_score(input_string)

def calculate_correctness_score(dialog):
    
    dialog_str = "\n".join([f"Teacher asks: {dialog[i]}\nStudent answers: {dialog[i+1]}" for i in range(0, len(dialog), 2)])
    
    prompt = f"Assuming you are a linguistic expert, your task is to assess the correctness of the following dialogue generated by an AI system. This dialogue is structured as a teacher-student interaction centered around teaching a passage from a textbook, only the teacher part is generated by AI. When we say 'correctness', we're asking: Does the dialogue provide accurate and factual question for each response? \n\n Please provide a coherence score from 0 to 10, where 0 signifies all questions are not correct and 10 denotes excellent correctness. The dialog is: \n\n{dialog_str}\n\n Please provide me with the score only in your response in this format: Score:<number>"
    print('prompt:',prompt)
    print('__________________________generated______________________________________________')
    # inputs = tokenizer.encode(prompt, return_tensors='pt', truncation=True, max_length=512)
    # outputs = model.generate(inputs, max_length=512, do_sample=True)
    result = generate_response0(prompt,'gpt-4-0314')
    input_string = result['choices'][0]['message']['content']
    extract_score(input_string)
    return extract_score(input_string)
        # Placeholder logic to extract score from generated text
        # This assumes that the model's response is a numerical score, which may not always be the case
        # coherence_score = float(generated.split()[-1])
        # coherence_scores.append(coherence_score)

    # avg_coherence = sum(coherence_scores) / len(coherence_scores)

    # df = pd.DataFrame({
    #     'coherence': [avg_coherence],
    # })

    # return df

# file_path = '/cluster/scratch/wangjun/dialogue_inpainting5_18_flan_lora_xl/work/ukp/huggingface/6_27_algebra_search/HuggingfaceSearchJob.8FtuwoC7t0JX/output/search_output_post.json'
dialog = [
    "Hello, how are you?",
    "I want a cup of coffee."
]
# score = calculate_correctness_score(dialog)
score = calculate_coherence_score(dialog)
print('original text',score)
print('score:',extract_score(score))
